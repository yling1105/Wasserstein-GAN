{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lingyaobin/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import sklearn.datasets\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.plot\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'wgan-gp' # wgan or wgan-gp\n",
    "DATASET = '8gaussians' # 8gaussians, 25gaussians, swissroll\n",
    "DIM = 512 # Model dimensionality\n",
    "FIXED_GENERATOR = False # whether to hold the generator fixed at real data plus\n",
    "                        # Gaussian noise, as in the plots in the paper\n",
    "LAMBDA = .1 # Smaller lambda makes things faster for toy tasks, but isn't\n",
    "            # necessary if you increase CRITIC_ITERS enough\n",
    "CRITIC_ITERS = 5 # How many critic iterations per generator iteration\n",
    "BATCH_SIZE = 256 # Batch size\n",
    "ITERS = 100000 # how many generator iterations to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 256\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDATASET: 8gaussians\n",
      "\tDIM: 512\n",
      "\tFIXED_GENERATOR: False\n",
      "\tITERS: 100000\n",
      "\tLAMBDA: 0.1\n",
      "\tMODE: wgan-gp\n"
     ]
    }
   ],
   "source": [
    "lib.print_model_settings(locals().copy())\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name+'.Linear',\n",
    "        n_in,\n",
    "        n_out,\n",
    "        inputs,\n",
    "        initialization='he'\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(n_samples, real_data):\n",
    "    if FIXED_GENERATOR:\n",
    "        return real_data + (1.*tf.random_normal(tf.shape(real_data)))\n",
    "    else:\n",
    "        noise = tf.random_normal([n_samples, 2])\n",
    "        output = ReLULayer('Generator.1', 2, DIM, noise)\n",
    "        output = ReLULayer('Generator.2', DIM, DIM, output)\n",
    "        output = ReLULayer('Generator.3', DIM, DIM, output)\n",
    "        output = lib.ops.linear.Linear('Generator.4', DIM, 2, output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(inputs):\n",
    "    output = ReLULayer('Discriminator.1', 2, DIM, inputs)\n",
    "    output = ReLULayer('Discriminator.2', DIM, DIM, output)\n",
    "    output = ReLULayer('Discriminator.3', DIM, DIM, output)\n",
    "    output = lib.ops.linear.Linear('Discriminator.4', DIM, 1, output)\n",
    "    return tf.reshape(output, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lingyaobin/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "real_data = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "fake_data = Generator(BATCH_SIZE, real_data)\n",
    "\n",
    "disc_real = Discriminator(real_data)\n",
    "disc_fake = Discriminator(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator params:\n",
      "\tGenerator.1.Linear/Generator.1.Linear.W:0\t(2, 512)\n",
      "\tGenerator.1.Linear/Generator.1.Linear.b:0\t(512,)\n",
      "\tGenerator.2.Linear/Generator.2.Linear.W:0\t(512, 512)\n",
      "\tGenerator.2.Linear/Generator.2.Linear.b:0\t(512,)\n",
      "\tGenerator.3.Linear/Generator.3.Linear.W:0\t(512, 512)\n",
      "\tGenerator.3.Linear/Generator.3.Linear.b:0\t(512,)\n",
      "\tGenerator.4/Generator.4.W:0\t(512, 2)\n",
      "\tGenerator.4/Generator.4.b:0\t(2,)\n",
      "Discriminator params:\n",
      "\tDiscriminator.1.Linear/Discriminator.1.Linear.W:0\t(2, 512)\n",
      "\tDiscriminator.1.Linear/Discriminator.1.Linear.b:0\t(512,)\n",
      "\tDiscriminator.2.Linear/Discriminator.2.Linear.W:0\t(512, 512)\n",
      "\tDiscriminator.2.Linear/Discriminator.2.Linear.b:0\t(512,)\n",
      "\tDiscriminator.3.Linear/Discriminator.3.Linear.W:0\t(512, 512)\n",
      "\tDiscriminator.3.Linear/Discriminator.3.Linear.b:0\t(512,)\n",
      "\tDiscriminator.4/Discriminator.4.W:0\t(512, 1)\n",
      "\tDiscriminator.4/Discriminator.4.b:0\t(1,)\n"
     ]
    }
   ],
   "source": [
    "disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "gen_cost = -tf.reduce_mean(disc_fake)\n",
    "\n",
    "# WGAN gradient penalty\n",
    "if MODE == 'wgan-gp':\n",
    "    alpha = tf.random_uniform(\n",
    "        shape=[BATCH_SIZE,1],\n",
    "        minval=0.,\n",
    "        maxval=1.\n",
    "    )\n",
    "    interpolates = alpha*real_data + ((1-alpha)*fake_data)\n",
    "    disc_interpolates = Discriminator(interpolates)\n",
    "    gradients = tf.gradients(disc_interpolates, [interpolates])[0]\n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "    gradient_penalty = tf.reduce_mean((slopes-1)**2)\n",
    "\n",
    "    disc_cost += LAMBDA*gradient_penalty\n",
    "\n",
    "disc_params = lib.params_with_name('Discriminator')\n",
    "gen_params = lib.params_with_name('Generator')\n",
    "\n",
    "if MODE == 'wgan-gp':\n",
    "    disc_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4,\n",
    "        beta1=0.5,\n",
    "        beta2=0.9\n",
    "    ).minimize(\n",
    "        disc_cost,\n",
    "        var_list=disc_params\n",
    "    )\n",
    "    if len(gen_params) > 0:\n",
    "        gen_train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=1e-4,\n",
    "            beta1=0.5,\n",
    "            beta2=0.9\n",
    "        ).minimize(\n",
    "            gen_cost,\n",
    "            var_list=gen_params\n",
    "        )\n",
    "    else:\n",
    "        gen_train_op = tf.no_op()\n",
    "\n",
    "else:\n",
    "    disc_train_op = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(\n",
    "        disc_cost,\n",
    "        var_list=disc_params\n",
    "    )\n",
    "    if len(gen_params) > 0:\n",
    "        gen_train_op = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(\n",
    "            gen_cost,\n",
    "            var_list=gen_params\n",
    "        )\n",
    "    else:\n",
    "        gen_train_op = tf.no_op()\n",
    "\n",
    "\n",
    "    # Build an op to do the weight clipping\n",
    "    clip_ops = []\n",
    "    for var in disc_params:\n",
    "        clip_bounds = [-.01, .01]\n",
    "        clip_ops.append(\n",
    "            tf.assign(\n",
    "                var,\n",
    "                tf.clip_by_value(var, clip_bounds[0], clip_bounds[1])\n",
    "            )\n",
    "        )\n",
    "    clip_disc_weights = tf.group(*clip_ops)\n",
    "\n",
    "print(\"Generator params:\")\n",
    "for var in lib.params_with_name('Generator'):\n",
    "    print(\"\\t{}\\t{}\".format(var.name, var.get_shape()))\n",
    "print(\"Discriminator params:\")\n",
    "for var in lib.params_with_name('Discriminator'):\n",
    "    print(\"\\t{}\\t{}\".format(var.name, var.get_shape()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset iterator\n",
    "def inf_train_gen():\n",
    "    if DATASET == '25gaussians':\n",
    "\n",
    "        dataset = []\n",
    "        for i in range(100000/25):\n",
    "            for x in xrange(-2, 3):\n",
    "                for y in xrange(-2, 3):\n",
    "                    point = np.random.randn(2)*0.05\n",
    "                    point[0] += 2*x\n",
    "                    point[1] += 2*y\n",
    "                    dataset.append(point)\n",
    "        dataset = np.array(dataset, dtype='float32')\n",
    "        np.random.shuffle(dataset)\n",
    "        dataset /= 2.828 # stdev\n",
    "        while True:\n",
    "            for i in range(len(dataset)/BATCH_SIZE):\n",
    "                yield dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    elif DATASET == 'swissroll':\n",
    "\n",
    "        while True:\n",
    "            data = sklearn.datasets.make_swiss_roll(\n",
    "                n_samples=BATCH_SIZE,\n",
    "                noise=0.25\n",
    "            )[0]\n",
    "            data = data.astype('float32')[:, [0, 2]]\n",
    "            data /= 7.5 # stdev plus a little\n",
    "            yield data\n",
    "\n",
    "    elif DATASET == '8gaussians':\n",
    "\n",
    "        scale = 2.\n",
    "        centers = [\n",
    "            (1,0),\n",
    "            (-1,0),\n",
    "            (0,1),\n",
    "            (0,-1),\n",
    "            (1./np.sqrt(2), 1./np.sqrt(2)),\n",
    "            (1./np.sqrt(2), -1./np.sqrt(2)),\n",
    "            (-1./np.sqrt(2), 1./np.sqrt(2)),\n",
    "            (-1./np.sqrt(2), -1./np.sqrt(2))\n",
    "        ]\n",
    "        centers = [(scale*x,scale*y) for x,y in centers]\n",
    "        while True:\n",
    "            dataset = []\n",
    "            for i in range(BATCH_SIZE):\n",
    "                point = np.random.randn(2)*.02\n",
    "                center = random.choice(centers)\n",
    "                point[0] += center[0]\n",
    "                point[1] += center[1]\n",
    "                dataset.append(point)\n",
    "            dataset = np.array(dataset, dtype='float32')\n",
    "            dataset /= 1.414 # stdev\n",
    "            yield dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_index = [0]\n",
    "def generate_image(true_dist):\n",
    "    \"\"\"\n",
    "    Generates and saves a plot of the true distribution, the generator, and the\n",
    "    critic.\n",
    "    \"\"\"\n",
    "    N_POINTS = 128\n",
    "    RANGE = 3\n",
    "\n",
    "    points = np.zeros((N_POINTS, N_POINTS, 2), dtype='float32')\n",
    "    points[:,:,0] = np.linspace(-RANGE, RANGE, N_POINTS)[:,None]\n",
    "    points[:,:,1] = np.linspace(-RANGE, RANGE, N_POINTS)[None,:]\n",
    "    points = points.reshape((-1,2))\n",
    "    samples, disc_map = session.run(\n",
    "        [fake_data, disc_real],\n",
    "        feed_dict={real_data:points}\n",
    "    )\n",
    "    disc_map = session.run(disc_real, feed_dict={real_data:points})\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    x = y = np.linspace(-RANGE, RANGE, N_POINTS)\n",
    "    plt.contour(x,y,disc_map.reshape((len(x), len(y))).transpose())\n",
    "\n",
    "    plt.scatter(true_dist[:, 0], true_dist[:, 1], c='orange',  marker='+')\n",
    "    plt.scatter(samples[:, 0],    samples[:, 1],c='green', marker='+')\n",
    "\n",
    "    plt.savefig('frame'+str(frame_index[0])+'.eps')\n",
    "    frame_index[0] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lingyaobin/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [9:27:02<00:00,  2.94it/s]       \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    gen = inf_train_gen()\n",
    "    for iteration in tqdm(range(ITERS)):\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(gen_train_op)\n",
    "        # Train critic\n",
    "        for i in range(CRITIC_ITERS):\n",
    "            _data = gen.__next__()\n",
    "            _disc_cost, _ = session.run(\n",
    "                [disc_cost, disc_train_op],\n",
    "                feed_dict={real_data: _data}\n",
    "            )\n",
    "            if MODE == 'wgan':\n",
    "                _ = session.run([clip_disc_weights])\n",
    "        # Write logs and save samples\n",
    "        lib.plot.plot('disc cost', _disc_cost)\n",
    "        if iteration % 10000 == 9999:\n",
    "            #lib.plot.flush()\n",
    "            generate_image(_data)\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
